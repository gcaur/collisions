{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dad2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, grid_search, datasets\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from texttable import Texttable\n",
    "import texttable as tt\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statistics import mean\n",
    "import sys, os\n",
    "\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "#import lightgbm as lgb\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "import sklearn.cluster as cluster\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import curve_fit\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "import seaborn as sns\n",
    "import array\n",
    "from sklearn import metrics\n",
    "pd.options.mode.chained_assignment = None\n",
    "import pandas_profiling\n",
    "\n",
    "from plotly.offline import iplot,init_notebook_mode, plot as pplot\n",
    "from plotly import graph_objs as go\n",
    "init_notebook_mode()\n",
    "import plotly.plotly as py\n",
    "py.sign_in('emaad', 'VzbDk0qpBaRDSJevZ3bo')\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLCollisions(object):\n",
    "    def __init__(self, dataframe, metric2opt, FI=False):\n",
    "        \n",
    "        maindataframe = dataframe\n",
    "        \n",
    "        maindataframe = maindataframe[maindataframe['Mass of Remnant'] != 0] #Removing Zeroes\n",
    "                \n",
    "        maindataframe[\"Impactor Mass\"] = maindataframe[\"Impactor Mass/Target Mass\"]*maindataframe[\"Target Mass\"] #Getting Mass of Impactor\n",
    "\n",
    "        maindataframe[\"Xi\"] = (maindataframe[\"Mass of Remnant\"] - maindataframe[\"Target Mass\"])/(maindataframe[\"Impactor Mass/Target Mass\"]*maindataframe[\"Target Mass\"]) #Calculating Xi (efficiency)\n",
    "        maindataframe[\"RemTarg\"] = maindataframe[\"Mass of Remnant\"]/maindataframe[\"Target Mass\"]\n",
    "        maindataframe[\"RemTot\"] = maindataframe[\"Mass of Remnant\"]/(maindataframe[\"Target Mass\"]+maindataframe[\"Impactor Mass\"])\n",
    "\n",
    "        #Classifying by Hand\n",
    "        xilist = maindataframe[\"Xi\"].tolist()\n",
    "        tar = maindataframe[\"Target Mass\"].tolist()\n",
    "        imp = maindataframe[\"Impactor Mass\"].tolist()\n",
    "        \n",
    "        #Classifying\n",
    "        clsfr = []\n",
    "        for i in range(0,len(xilist)):\n",
    "            if (xilist[i] < tar[i] and xilist[i] >= 0.1*tar[i]):\n",
    "                clsfr.append(0) #Erosion = MLR = 0.1-0.9MTarg - Xi below 0, above MTarg/Mimp\n",
    "            elif (xilist[i] < (tar[i]+ 0.9*imp[i]) and xilist[i] > (tar[i]+ 0.1*imp[i])):\n",
    "                clsfr.append(1) #Partial Accretion = MLR = MTarg + 0.1-0.9MImp - Xi in [0.1-0.9]\n",
    "            elif (xilist[i] >= (tar[i]+ 0.9*imp[i])):\n",
    "                clsfr.append(2) #Perfect merger = MLR = MTarg + MImp - Xi = 1\n",
    "            else:\n",
    "                clsfr.append(3) #Hit and run = MLR = MTarg - Xi = 0\n",
    "\n",
    "        maindataframe[\"Group\"] = clsfr\n",
    "\n",
    "        group_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle']]\n",
    "        group_y=maindataframe['Group']\n",
    "        \n",
    "        \n",
    "        \n",
    "        xi_wgroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle','Group']]\n",
    "        xi_wgroup_y=maindataframe['Xi']\n",
    "        \n",
    "        xi_nogroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle']]\n",
    "        xi_nogroup_y=maindataframe['Xi'] \n",
    "        \n",
    "        \n",
    "        \n",
    "        remtarg_wgroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle','Group']]\n",
    "        remtarg_wgroup_y=maindataframe['RemTarg']\n",
    "        \n",
    "        remtarg_nogroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle']]\n",
    "        remtarg_nogroup_y=maindataframe['RemTarg'] \n",
    "        \n",
    "        \n",
    "        \n",
    "        remtot_wgroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle','Group']]\n",
    "        remtot_wgroup_y=maindataframe['RemTot']\n",
    "        \n",
    "        remtot_nogroup_X=maindataframe[['Target Mass', 'Impactor Mass/Target Mass', 'Impact Velocity', 'Impact Angle']]\n",
    "        remtot_nogroup_y=maindataframe['RemTot'] \n",
    "        \n",
    "        \n",
    "        \n",
    "        group_X_train, group_X_test, group_y_train, group_y_test = train_test_split(group_X, group_y, test_size=0.25, random_state=0)\n",
    "        group_data_TRAIN=pd.concat([group_X_train, group_y_train], axis=1)\n",
    "        group_data_TEST=pd.concat([group_X_test, group_y_test],axis=1)\n",
    "        \n",
    "        self.group_X_train = group_X_train\n",
    "        self.group_y_train = group_y_train\n",
    "        self.group_X_test = group_X_test\n",
    "        self.group_y_test = group_y_test\n",
    "        self.group_data_TRAIN = group_data_TRAIN\n",
    "        self.group_data_TEST = group_data_TEST\n",
    "        \n",
    "        \n",
    "\n",
    "        xi_wgroup_X_train, xi_wgroup_X_test, xi_wgroup_y_train, xi_wgroup_y_test = train_test_split(xi_wgroup_X, xi_wgroup_y, test_size=0.25, random_state=0)\n",
    "        xi_wgroup_data_TRAIN=pd.concat([xi_wgroup_X_train, xi_wgroup_y_train], axis=1)\n",
    "        xi_wgroup_data_TEST=pd.concat([xi_wgroup_X_test, xi_wgroup_y_test],axis=1) \n",
    "        \n",
    "        xi_nogroup_X_train, xi_nogroup_X_test, xi_nogroup_y_train, xi_nogroup_y_test = train_test_split(xi_nogroup_X, xi_nogroup_y, test_size=0.25, random_state=0)\n",
    "        xi_nogroup_data_TRAIN=pd.concat([xi_nogroup_X_train, xi_nogroup_y_train], axis=1)\n",
    "        xi_nogroup_data_TEST=pd.concat([xi_nogroup_X_test, xi_nogroup_y_test],axis=1)\n",
    "        \n",
    "        self.xi_wgroup_X_train = xi_wgroup_X_train\n",
    "        self.xi_wgroup_y_train = xi_wgroup_y_train\n",
    "        self.xi_wgroup_X_test = xi_wgroup_X_test\n",
    "        self.xi_wgroup_y_test = xi_wgroup_y_test\n",
    "        self.xi_wgroup_data_TRAIN = xi_wgroup_data_TRAIN\n",
    "        self.xi_wgroup_data_TEST = xi_wgroup_data_TEST\n",
    "        \n",
    "        self.xi_nogroup_X_train = xi_nogroup_X_train\n",
    "        self.xi_nogroup_y_train = xi_nogroup_y_train\n",
    "        self.xi_nogroup_X_test = xi_nogroup_X_test\n",
    "        self.xi_nogroup_y_test = xi_nogroup_y_test\n",
    "        self.xi_nogroup_data_TRAIN = xi_nogroup_data_TRAIN\n",
    "        self.xi_nogroup_data_TEST = xi_nogroup_data_TEST\n",
    "        \n",
    "        \n",
    "        \n",
    "        remtarg_wgroup_X_train, remtarg_wgroup_X_test, remtarg_wgroup_y_train, remtarg_wgroup_y_test = train_test_split(remtarg_wgroup_X, remtarg_wgroup_y, test_size=0.25, random_state=0)\n",
    "        remtarg_wgroup_data_TRAIN=pd.concat([remtarg_wgroup_X_train, remtarg_wgroup_y_train], axis=1)\n",
    "        remtarg_wgroup_data_TEST=pd.concat([remtarg_wgroup_X_test, remtarg_wgroup_y_test],axis=1)\n",
    "        \n",
    "        remtarg_nogroup_X_train, remtarg_nogroup_X_test, remtarg_nogroup_y_train, remtarg_nogroup_y_test = train_test_split(remtarg_nogroup_X, remtarg_nogroup_y, test_size=0.25, random_state=0)\n",
    "        remtarg_nogroup_data_TRAIN=pd.concat([remtarg_nogroup_X_train, remtarg_nogroup_y_train], axis=1)\n",
    "        remtarg_nogroup_data_TEST=pd.concat([remtarg_nogroup_X_test, remtarg_nogroup_y_test],axis=1)\n",
    "        \n",
    "        self.remtarg_wgroup_X_train = remtarg_wgroup_X_train\n",
    "        self.remtarg_wgroup_y_train = remtarg_wgroup_y_train\n",
    "        self.remtarg_wgroup_X_test = remtarg_wgroup_X_test\n",
    "        self.remtarg_wgroup_y_test = remtarg_wgroup_y_test\n",
    "        self.remtarg_wgroup_data_TRAIN = remtarg_wgroup_data_TRAIN\n",
    "        self.remtarg_wgroup_data_TEST = remtarg_wgroup_data_TEST\n",
    "        \n",
    "        self.remtarg_nogroup_X_train = remtarg_nogroup_X_train\n",
    "        self.remtarg_nogroup_y_train = remtarg_nogroup_y_train\n",
    "        self.remtarg_nogroup_X_test = remtarg_nogroup_X_test\n",
    "        self.remtarg_nogroup_y_test = remtarg_nogroup_y_test\n",
    "        self.remtarg_nogroup_data_TRAIN = remtarg_nogroup_data_TRAIN\n",
    "        self.remtarg_nogroup_data_TEST = remtarg_nogroup_data_TEST\n",
    "        \n",
    "        \n",
    "        \n",
    "        remtot_wgroup_X_train, remtot_wgroup_X_test, remtot_wgroup_y_train, remtot_wgroup_y_test = train_test_split(remtot_wgroup_X, remtot_wgroup_y, test_size=0.25, random_state=0)\n",
    "        remtot_wgroup_data_TRAIN=pd.concat([remtot_wgroup_X_train, remtot_wgroup_y_train], axis=1)\n",
    "        remtot_wgroup_data_TEST=pd.concat([remtot_wgroup_X_test, remtot_wgroup_y_test],axis=1)\n",
    "        \n",
    "        remtot_nogroup_X_train, remtot_nogroup_X_test, remtot_nogroup_y_train, remtot_nogroup_y_test = train_test_split(remtot_nogroup_X, remtot_nogroup_y, test_size=0.25, random_state=0)\n",
    "        remtot_nogroup_data_TRAIN=pd.concat([remtot_nogroup_X_train, remtot_nogroup_y_train], axis=1)\n",
    "        remtot_nogroup_data_TEST=pd.concat([remtot_nogroup_X_test, remtot_nogroup_y_test],axis=1)\n",
    "        \n",
    "        self.remtot_wgroup_X_train = remtot_wgroup_X_train\n",
    "        self.remtot_wgroup_y_train = remtot_wgroup_y_train\n",
    "        self.remtot_wgroup_X_test = remtot_wgroup_X_test\n",
    "        self.remtot_wgroup_y_test = remtot_wgroup_y_test\n",
    "        self.remtot_wgroup_data_TRAIN = remtot_wgroup_data_TRAIN\n",
    "        self.remtot_wgroup_data_TEST = remtot_wgroup_data_TEST\n",
    "        \n",
    "        self.remtot_nogroup_X_train = remtot_nogroup_X_train\n",
    "        self.remtot_nogroup_y_train = remtot_nogroup_y_train\n",
    "        self.remtot_nogroup_X_test = remtot_nogroup_X_test\n",
    "        self.remtot_nogroup_y_test = remtot_nogroup_y_test\n",
    "        self.remtot_nogroup_data_TRAIN = remtot_nogroup_data_TRAIN\n",
    "        self.remtot_nogroup_data_TEST = remtot_nogroup_data_TEST\n",
    "        \n",
    "        maxdepth_range=np.arange(1,21,2)\n",
    "        nestimators_range=np.arange(50,100,5)\n",
    "        \n",
    "        self.FI=FI\n",
    "        \n",
    "        self.metric2opt = metric2opt\n",
    "        self.metric=self.metric2opt\n",
    "        self.maxdepth_range = maxdepth_range\n",
    "        self.nestimators_range = nestimators_range\n",
    "        self.cv = KFold(n_splits=4, random_state=0) #random state fixed to get scores and prediction same in crossval\n",
    "        \n",
    "\n",
    "#------------------------------------------------------------------------------  \n",
    "\n",
    "    def createfeatures(self,data):\n",
    "\n",
    "        # LOGS of original 4 features\n",
    "        data['log Target Mass']= np.log10(data['Target Mass'])\n",
    "        data[\"Impactor Mass\"] = data[\"Impactor Mass/Target Mass\"]*data[\"Target Mass\"] #Mass of the Impactor in Earth Masses\n",
    "        data['log Impactor Mass']=np.log10(data['Impactor Mass'])\n",
    "        data['log Impactor log Target'] = data['log Impactor Mass']/ data['log Target Mass']\n",
    "\n",
    "\n",
    "        # NORMALIZING ML TARGET\n",
    "        #data[\"Normalized MLR\"] = data[\"Remnant Mass\"]/data[\"Target Mass\"] #Normalizing mass of largest remnant to total mass  \n",
    "        #data[\"NormTot MLR\"] = data[\"Remnant Mass\"]/(data[\"Target Mass\"]+data[\"Impactor Mass\"]) #Normalizing mass of largest remnant to total mass\n",
    "        #data['log Mass of Remnant']=np.log10(data['Remnant Mass'])\n",
    "        #data[\"Xi\"] = (data[\"Remnant Mass\"] - data[\"Target Mass\"])/data[\"Impactor Mass\"] #Calculating Xi (efficiency)\n",
    "\n",
    "        data[\"Mass Total\"] = data[\"Impactor Mass\"]+data[\"Target Mass\"] #Total Mass in Earth Masses\n",
    "\n",
    "        impact_angleMLR = data[\"Impact Angle\"].tolist() #Making a list from the Impact Angle column\n",
    "\n",
    "        data[\"Rci\"] = (((data[\"Target Mass\"]+data[\"Impactor Mass\"])/(1333.33*np.pi)))**((1/3)) #Spherical radius of the combined projectile and target masses (normalized to total mass) at a density of ρ ≡ 1000 kg/m^3\n",
    "        data[\"Target Radius\"] = (((data[\"Target Mass\"])/(1333.33*np.pi)))**((1/3)) #Radius of the target (normalized to total mass) at a density of ρ ≡ 1000 kg/m^3\n",
    "        data[\"Impactor Radius\"] = (((data[\"Impactor Mass\"])/(1333.33*np.pi)))**((1/3)) #Radius of the impactor in (normalized to total mass) at a density of ρ ≡ 1000 kg/m^3\n",
    "\n",
    "        vstarcoff1 = ((32*np.pi*1.9)/5)**0.5 #VStar Coefficient 1 to calculate V* (critical impact velocity)\n",
    "        vstarcoff2 = ((1000*6.674*(10**-11)))**0.5 #VStar Coefficient 2 to calculate V* (critical impact velocity)\n",
    "        data[\"vstarcoff3\"] = ((750*np.pi)/data[\"Mass Total\"])**(1/3) #VStar Coefficient 3 to calculate V* (critical impact velocity)\n",
    "        data[\"Vstar\"] = data[\"vstarcoff3\"]*vstarcoff2*vstarcoff1 #Critical Impact Velocity required to disperse half of the total mass for a specific impact scenario\n",
    "\n",
    "        data[\"QR\"] = (0.5*data[\"Impact Velocity\"]*data[\"Impact Velocity\"])/data[\"Mass Total\"] #Center of mass specific impact energy\n",
    "        data[\"QRD\"] = (0.5*(data[\"Vstar\"]*data[\"Vstar\"]))/data[\"Mass Total\"] #Catastrophic disruption threshold\n",
    "\n",
    "        sinangle = [] #Getting the sine of the Impact Angle\n",
    "        for i in range(0,len(impact_angleMLR)):\n",
    "            x = impact_angleMLR[i]\n",
    "            rad = math.radians(x)\n",
    "            b = math.sin(rad)\n",
    "            sinangle.append(b)\n",
    "\n",
    "        data[\"Impact Parameter\"] = sinangle #Creating a column with the sine of the angle\n",
    "        data[\"B\"] = (data[\"Impactor Radius\"]+data[\"Target Radius\"])*data[\"Impact Parameter\"] #Sum of Radius multiplied by sine of angle\n",
    "        data[\"l\"] = (data[\"Impactor Radius\"]+data[\"Target Radius\"]) - data[\"B\"] #Length of the projectile impacting the target\n",
    "        data[\"alpha\"] = ((3*data[\"Impactor Radius\"]*(data[\"l\"]**2))-(data[\"l\"]**3))/(4*(data[\"Impactor Radius\"]**3)) #Mass fraction of the projectile estimated to be involved in the collision\n",
    "        data[\"mualpha\"] = (data[\"alpha\"]*data[\"Impactor Mass\"]*data[\"Target Mass\"])/((data[\"alpha\"]*data[\"Impactor Mass\"])+data[\"Target Mass\"]) #Reduced mass that takes into account the effect of impact angle on QRD\n",
    "        data[\"QRmu\"] = (data[\"QR\"])/data[\"mualpha\"] #The difference of impact energy between a head-on impact by a projectile of mass M1 and a head-on impact by a projectile of mass alphaM1\n",
    "\n",
    "        data[\"Sum Radius\"] = data[\"Impactor Radius\"]+data[\"Target Radius\"] #Sum of Radii as calculated above\n",
    "\n",
    "        data[\"bcrit\"] = data[\"Target Radius\"]/(data[\"Target Radius\"]+data[\"Impactor Radius\"]) #Critical impact parameter which shows transition from non-grazing to grazing collision (if bcrit < b (Impact Parameter), it is a Grazing Collision, where less than half of the projectile interacts or hits the target)\n",
    "\n",
    "        data[\"gamma\"] = data[\"Impactor Mass\"]/data[\"Target Mass\"] #Calculating weight ratio of Umpactor Mass/Target Mass and naming it gamma\n",
    "\n",
    "        data[\"VinfVesc\"] = (((data[\"Impact Velocity\"])**2)-1)**0.5 #Calculating Vinf/Vesc based on the fact that Impact Velocity is Vimpact/Vescape, and Vinf/Vesc = SQRT((Vinf/Vesc)^2 - 1)\n",
    "\n",
    "        data['vel x angle']=data['Impact Velocity']*data['Impact Angle']\n",
    "        data['vel x angle2']=data['Impact Velocity']*data['Impact Angle']**2\n",
    "        data['vel x angle3']=data['Impact Velocity']*data['Impact Angle']**3\n",
    "        data['vel2 x angle']=data['Impact Velocity']**2*data['Impact Angle']\n",
    "        data['vel3 x angle']=data['Impact Velocity']**3*data['Impact Angle']\n",
    "        \n",
    "        data['exp vel x angle']=np.exp(data['Impact Velocity'])*data['Impact Angle']\n",
    "        data['sigmoid']= 1./(1.+ np.exp(data['Impact Velocity']))\n",
    "        return data\n",
    "\n",
    "    def outlierdetector(self,X_true,y_true,y_pred,errorbound):\n",
    "        partdata = X_true.copy()\n",
    "        partdata[\"Actual MLR\"] = y_true\n",
    "        partdata[\"Predicted MLR\"] = y_pred\n",
    "        partdata[\"Error\"] = np.abs(partdata[\"Actual MLR\"]-partdata[\"Predicted MLR\"])\n",
    "        baddata = partdata[partdata['Error'] > errorbound]\n",
    "        gooddata = partdata[partdata['Error'] <= errorbound]\n",
    "\n",
    "        print('Number of samples predicted poorly: %i' % len(baddata.index))\n",
    "        print('MSE of poorly-predicted samples:  %f' % metrics.mean_squared_error(baddata[\"Predicted MLR\"], baddata[\"Actual MLR\"]))\n",
    "        print('MSE of well-predicted samples:  %f' % metrics.mean_squared_error(gooddata[\"Predicted MLR\"], gooddata[\"Actual MLR\"]))\n",
    "\n",
    "        #tracegood = go.Scatter(x=gooddata[\"Actual MLR\"],y=gooddata[\"Predicted MLR\"],name=\"Good Data\", mode= 'markers',marker= dict(size= 3+3*gooddata['Impact Velocity'],line= dict(width=1), color= gooddata['Impact Angle'],colorscale='Blues',showscale=False))\n",
    "        #tracebad = go.Scatter(x=baddata[\"Actual MLR\"],y=baddata[\"Predicted MLR\"],name=\"Bad Data\", mode= 'markers',marker= dict(size= 3+3*baddata['Impact Velocity'],line= dict(width=1), color= baddata['Impact Angle'],colorscale='Reds',showscale=False))\n",
    "        #traceact = go.Scatter(x=y_true,y=y_pred,name=\"All Data\", mode= 'markers',marker= dict(size= 3+3*X_true['Impact Velocity'],line= dict(width=1), color= X_true['Impact Angle'],colorscale='Viridis',showscale=False))\n",
    "        #traceline = go.Scatter(x = [min(y_true),max(y_true)],y = [min(y_true),max(y_true)],mode = 'lines',name = '1-1 Line',opacity=0.25)\n",
    "\n",
    "        #dataplot = [tracegood,tracebad,traceact,traceline]\n",
    "        #return py.iplot(dataplot)\n",
    "\n",
    "    #def outlierdetectdata(self, X_true,y_true,y_pred,errorbound):\n",
    "     #   partdata = X_true\n",
    "      #  partdata[\"Actual MLR\"] = y_true\n",
    "       # partdata[\"Predicted MLR\"] = y_pred\n",
    "        #partdata[\"Error\"] = np.abs(partdata[\"Actual MLR\"]-partdata[\"Predicted MLR\"])/np.abs(partdata[\"Actual MLR\"])\n",
    "        #baddata = partdata[partdata['Error'] > errorbound]\n",
    "        #gooddata = partdata[partdata['Error'] <= errorbound]\n",
    "\n",
    "        #return(gooddata, baddata)\n",
    "    \n",
    "    #-----XGBOOST CLASS SECTION--------#\n",
    "    \n",
    "    def xgbCV_scores(self, x_data, y_data, params):\n",
    "        # cross validation with any params (needs to be a dictionary with max_depth and n_estimators)\n",
    "        # eg. params={'max_depth': 5, 'n_estimators': 10}\n",
    "        \n",
    "        # instantiating model:\n",
    "        xgbmodel=XGBRegressor(max_depth = params['max_depth'], \n",
    "                              n_estimators=params['n_estimators'], \n",
    "                              gamma=0.3, n_jobs=-1)\n",
    "        \n",
    "        # Cross validation for prediction and scores with same seed\n",
    "        predictedCV = cross_val_predict(xgbmodel, x_data, y_data, cv=4)\n",
    "        \n",
    "        xgbmodel=XGBRegressor(max_depth = params['max_depth'], \n",
    "                              n_estimators=params['n_estimators'], \n",
    "                              gamma=0.3, n_jobs=-1)\n",
    "        \n",
    "        score=-cross_val_score(xgbmodel, x_data, y_data, scoring=self.metric, cv=4)\n",
    "        score_mse=score\n",
    "        if self.metric2opt != 'neg_mean_squared_error':\n",
    "            xgbmodel=XGBRegressor(max_depth = params['max_depth'], \n",
    "                              n_estimators=params['n_estimators'], \n",
    "                              gamma=0.3, n_jobs=-1)\n",
    "            score_mse=-cross_val_score(xgbmodel, x_data, y_data, scoring='neg_mean_squared_error', cv=4)\n",
    "            \n",
    "        return score, score_mse, predictedCV\n",
    "\n",
    "    def xgbGS(self,mltarget):\n",
    "        param_grid = {\n",
    "                      'max_depth': self.maxdepth_range,\n",
    "                      'n_estimators': self.nestimators_range\n",
    "                      }\n",
    "\n",
    "        # Initialize XGB and GridSearch\n",
    "        xgb = XGBRegressor(gamma=0.3, njobs=-1) \n",
    "        grid = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring=self.metric, cv=4)\n",
    "        print('Performing GridSearchCV with Metric:', self.metric2opt)\n",
    "        if mltarget == 'xi':\n",
    "            trainingset_X = self.xi_nogroup_X_train\n",
    "            trainingset_y = self.xi_nogroup_y_train\n",
    "        elif mltarget == 'remtot':\n",
    "            trainingset_X = self.remtot_nogroup_X_train\n",
    "            trainingset_y = self.remtot_nogroup_y_train\n",
    "        elif mltarget == 'remtarg':\n",
    "            trainingset_X = self.remtarg_nogroup_X_train\n",
    "            trainingset_y = self.remtarg_nogroup_y_train\n",
    "        elif mltarget == 'xifull':\n",
    "            trainingset_X = self.xi_nogroup_full_X_train\n",
    "            trainingset_y = self.xi_nogroup_y_train\n",
    "        elif mltarget == 'remtotfull':\n",
    "            trainingset_X = self.remtot_nogroup_full_X_train\n",
    "            trainingset_y = self.remtot_nogroup_y_train\n",
    "        elif mltarget == 'remtargfull':\n",
    "            trainingset_X = self.remtarg_nogroup_full_X_train\n",
    "            trainingset_y = self.remtarg_nogroup_y_train\n",
    "        else:\n",
    "            print('Error Found. Using Mass of Largest Remnant Normalized to Total Mass As Default')\n",
    "            trainingset_X = self.remtot_nogroup_X_train\n",
    "            trainingset_y = self.remtot_nogroup_y_train\n",
    "            \n",
    "        grid_result=grid.fit(trainingset_X, trainingset_y)\n",
    "\n",
    "        #print('Best Estimator:',grid_result.best_estimator_)\n",
    "        print('Best Parameters:', grid_result.best_params_)\n",
    "        print('Best Metric Score:', -grid_result.best_score_)\n",
    "        \n",
    "        \n",
    "        return grid_result.best_params_\n",
    "    \n",
    "    def xgbtrainmodel(self,X,y,params):\n",
    "        # RETRAIN WITH ALL THE DATA:\n",
    "        xgb = XGBRegressor(max_depth=params['max_depth'],\n",
    "                         n_estimators=params['n_estimators'],  \n",
    "                         gamma=0.3, n_jobs=-1)\n",
    "        xgb_final = xgb.fit(X,y)\n",
    "        features=X.columns.values.tolist()\n",
    "        self.FeatureImportScores=pd.DataFrame({'feature': features,'score': xgb_final.feature_importances_,})\n",
    "        \n",
    "        if self.FI is True:\n",
    "            print('----------')\n",
    "            print('NON-ZERO FEATURE IMPORTANCES:')\n",
    "            for i, f in enumerate(features):\n",
    "                if xgb_final.feature_importances_[i] > 0:\n",
    "                    print('%s: .... %2f' %(f, xgb_final.feature_importances_[i]))\n",
    "\n",
    "        \n",
    "        return xgb_final\n",
    "    \n",
    "    def xgbtest_unseendata(self, xgb_final,testX,testY):\n",
    "\n",
    "        y_test_pred = xgb_final.predict(testX)\n",
    "\n",
    "        print('Test Data Scores:')\n",
    "        #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(testY, y_test_pred)))\n",
    "        print('MAE : ....%2f' %(metrics.mean_absolute_error(testY, y_test_pred)))\n",
    "        print('MSE : ....%2f' %(metrics.mean_squared_error(testY, y_test_pred)))\n",
    "        print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(testY, y_test_pred))))\n",
    "        return y_test_pred\n",
    "    \n",
    "    \n",
    "    #-----NESTED CLASS SECTION--------#\n",
    "    \n",
    "    def nest_main(self,daataa,mltargetplanet):\n",
    "        \n",
    "        print(\"CLASS-SPECIFIC REGRESSOR TRAINING:\")\n",
    "        \n",
    "        \n",
    "        train_g0 = daataa[daataa[\"Group\"] == 0]\n",
    "        y_train_g0 = train_g0[mltargetplanet]\n",
    "        del train_g0[mltargetplanet]\n",
    "        X_train_g0 = train_g0\n",
    "        \n",
    "        model_g0 = XGBRegressor(gamma=0.3, n_jobs=-1) #XGBoost Model\n",
    "\n",
    "        parameters_g0 = {'max_depth':self.maxdepth_range,'n_estimators':self.nestimators_range}\n",
    "        xgbMLR_g0 = GridSearchCV(model_g0, parameters_g0)\n",
    "        xgbMLR_g0.fit(X_train_g0,y_train_g0)\n",
    "        bestparams_g0 = xgbMLR_g0.best_params_\n",
    "        newxgb_g0 = XGBRegressor(max_depth = bestparams_g0.get('max_depth'), n_estimators = bestparams_g0.get('n_estimators'), gamma = 0.3, n_jobs=-1)\n",
    "        newxgb_g0.fit(X_train_g0,y_train_g0)\n",
    "        #predictedCV0 = cross_val_predict(newxgb_g0, X_train_g0, y_train_g0, cv=self.cv)\n",
    "    \n",
    "        score0i=-cross_val_score(newxgb_g0, X_train_g0, y_train_g0, scoring=self.metric2opt, cv=4)\n",
    "            \n",
    "        score_mse0i=score0i\n",
    "            \n",
    "        if self.metric2opt != 'neg_mean_squared_error':\n",
    "            newxgb_g0 = XGBRegressor(max_depth = bestparams_g0.get('max_depth'), n_estimators = bestparams_g0.get('n_estimators'),gamma = 0.3, n_jobs=-1)\n",
    "            score_mse0i=-cross_val_score(newxgb_g0, X_train_g0, y_train_g0, scoring='neg_mean_squared_error', cv=self.cv)\n",
    "        \n",
    "        print('Class 0 Training Data MSE: %2f .... STDev: %2f' %(np.mean(score_mse0i),np.std(score_mse0i)))\n",
    "        print('Class 0 Training Data RMSE: %2f' %(np.sqrt(np.mean(score_mse0i))))\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "        ######\n",
    "        train_g1 = daataa[daataa[\"Group\"] == 1]\n",
    "        y_train_g1 = train_g1[mltargetplanet]\n",
    "        del train_g1[mltargetplanet]\n",
    "        X_train_g1 = train_g1\n",
    "        \n",
    "        model_g1 = XGBRegressor(gamma=0.3, n_jobs=-1) #XGBoost Model\n",
    "\n",
    "        parameters_g1 = {'max_depth':self.maxdepth_range,'n_estimators':self.nestimators_range}\n",
    "        xgbMLR_g1 = GridSearchCV(model_g1, parameters_g1)\n",
    "        xgbMLR_g1.fit(X_train_g1,y_train_g1)\n",
    "        bestparams_g1 = xgbMLR_g1.best_params_\n",
    "        newxgb_g1 = XGBRegressor(max_depth = bestparams_g1.get('max_depth'), n_estimators = bestparams_g1.get('n_estimators'), gamma = 0.3, n_jobs=-1)\n",
    "        newxgb_g1.fit(X_train_g1,y_train_g1)\n",
    "        #predictedCV1 = cross_val_predict(newxgb_g1, X_train_g1, y_train_g1, cv=self.cv)\n",
    "        \n",
    "        score1i=-cross_val_score(newxgb_g1, X_train_g1, y_train_g1, scoring=self.metric2opt, cv=4)\n",
    "            \n",
    "        score_mse1i=score1i\n",
    "            \n",
    "        if self.metric2opt != 'neg_mean_squared_error':\n",
    "            newxgb_g1 = XGBRegressor(max_depth = bestparams_g1.get('max_depth'), n_estimators = bestparams_g1.get('n_estimators'),gamma = 0.3, n_jobs=-1)\n",
    "            score_mse1i=-cross_val_score(newxgb_g1, X_train_g1, y_train_g1, scoring='neg_mean_squared_error', cv=self.cv)\n",
    "        \n",
    "        print('Class 1 Training Data MSE: %2f .... STDev: %2f' %(np.mean(score_mse1i),np.std(score_mse1i)))\n",
    "        print('Class 1 Training Data RMSE: %2f' %(np.sqrt(np.mean(score_mse1i))))\n",
    "        print('')\n",
    "        \n",
    "        #######\n",
    "        train_g2 = daataa[daataa[\"Group\"] == 2]\n",
    "        y_train_g2 = train_g2[mltargetplanet]\n",
    "        del train_g2[mltargetplanet]\n",
    "        X_train_g2 = train_g2\n",
    "        \n",
    "        model_g2 = XGBRegressor(gamma=0.3, n_jobs=-1) #XGBoost Model\n",
    "\n",
    "        parameters_g2 = {'max_depth':self.maxdepth_range,'n_estimators':self.nestimators_range}\n",
    "        xgbMLR_g2 = GridSearchCV(model_g2, parameters_g2)\n",
    "        xgbMLR_g2.fit(X_train_g2,y_train_g2)\n",
    "        bestparams_g2 = xgbMLR_g2.best_params_\n",
    "        newxgb_g2 = XGBRegressor(max_depth = bestparams_g2.get('max_depth'), n_estimators = bestparams_g2.get('n_estimators'), gamma = 0.3, n_jobs=-1)\n",
    "        newxgb_g2.fit(X_train_g2,y_train_g2)\n",
    "        #predictedCV2 = cross_val_predict(newxgb_g2, X_train_g2, y_train_g2, cv=self.cv)\n",
    "        \n",
    "        score2i=-cross_val_score(newxgb_g2, X_train_g2, y_train_g2, scoring=self.metric2opt, cv=4)\n",
    "            \n",
    "        score_mse2i=score2i\n",
    "            \n",
    "        if self.metric2opt != 'neg_mean_squared_error':\n",
    "            newxgb_g2 = XGBRegressor(max_depth = bestparams_g2.get('max_depth'), n_estimators = bestparams_g2.get('n_estimators'),gamma = 0.3, n_jobs=-1)\n",
    "            score_mse2=-cross_val_score(newxgb_g2, X_train_g2, y_train_g2, scoring='neg_mean_squared_error', cv=self.cv)\n",
    "        \n",
    "        print('Class 2 Training Data MSE: %2f .... STDev: %2f' %(np.mean(score_mse2i),np.std(score_mse2i)))\n",
    "        print('Class 2 Training Data RMSE: %2f' %(np.sqrt(np.mean(score_mse2i))))  \n",
    "        print('')\n",
    "        \n",
    "        #######\n",
    "        train_g3 = daataa[daataa[\"Group\"] == 3]\n",
    "        y_train_g3 = train_g3[mltargetplanet]\n",
    "        del train_g3[mltargetplanet]\n",
    "        X_train_g3 = train_g3\n",
    "        \n",
    "        model_g3 = XGBRegressor(gamma=0.3, n_jobs=-1) #XGBoost Model\n",
    "\n",
    "        parameters_g3 = {'max_depth':self.maxdepth_range,'n_estimators':self.nestimators_range}\n",
    "        xgbMLR_g3 = GridSearchCV(model_g3, parameters_g3)\n",
    "        xgbMLR_g3.fit(X_train_g3,y_train_g3)\n",
    "        bestparams_g3 = xgbMLR_g3.best_params_\n",
    "        newxgb_g3 = XGBRegressor(max_depth = bestparams_g3.get('max_depth'), n_estimators = bestparams_g3.get('n_estimators'),gamma = 0.3, n_jobs=-1)\n",
    "        newxgb_g3.fit(X_train_g3,y_train_g3)\n",
    "        #predictedCV3 = cross_val_predict(newxgb_g3, X_train_g3, y_train_g3, cv=self.cv)\n",
    "        \n",
    "        score3i=-cross_val_score(newxgb_g3, X_train_g3, y_train_g3, scoring=self.metric2opt, cv=4)\n",
    "\n",
    "        score_mse3i=score3i\n",
    "            \n",
    "        if self.metric2opt != 'neg_mean_squared_error':\n",
    "            newxgb_g3 = XGBRegressor(max_depth = bestparams_g3.get('max_depth'), n_estimators = bestparams_g3.get('n_estimators'),gamma = 0.3, n_jobs=-1)\n",
    "            score_mse3i=-cross_val_score(newxgb_g3, X_train_g3, y_train_g3, scoring='neg_mean_squared_error', cv=self.cv)\n",
    "        \n",
    "        print('Class 3 Training Data MSE: %2f .... STDev: %2f' %(np.mean(score_mse3i),np.std(score_mse3i)))\n",
    "        print('Class 3 Training Data RMSE: %2f' %(np.sqrt(np.mean(score_mse3i))))\n",
    "        \n",
    "        ###########################\n",
    "        \n",
    "        self.trainmatrixgroup = [train_g0,train_g1,train_g2,train_g3]\n",
    "        self.trainxgroup = [X_train_g0,X_train_g1,X_train_g3,X_train_g3]\n",
    "        self.trainygroup = [y_train_g0,y_train_g1,y_train_g2,y_train_g3]\n",
    "        self.regressormatrix = [newxgb_g0,newxgb_g1,newxgb_g2,newxgb_g3]\n",
    "        self.scorematrix = [score0i,score1i,score2i,score3i]\n",
    "        self.scoremsematrix = [score_mse0i,score_mse1i,score_mse2i,score_mse3i]\n",
    "        #self.predictCVmatrix = [predictedCV0,predictedCV1,predictedCV2,predictedCV3]\n",
    "        \n",
    "        ####################\n",
    "        \n",
    "        ###CLASSIFY###\n",
    "\n",
    "        dtrain = xgb.DMatrix(self.group_X_train, label=self.group_y_train)\n",
    "        dtest = xgb.DMatrix(self.group_X_test, label=self.group_y_test)\n",
    "        \n",
    "        self.dtrain = dtrain\n",
    "        self.dtest = dtest\n",
    "        \n",
    "        xgbclsfr = xgb.XGBClassifier(num_class = 5,eta = 0.6)\n",
    "\n",
    "        parametersMLR = {'max_depth':self.maxdepth_range,'n_estimators':self.nestimators_range}\n",
    "        xgb_classifier = GridSearchCV(xgbclsfr, parametersMLR)\n",
    "\n",
    "        xgb_classifier.fit(self.group_X_train,self.group_y_train)\n",
    "        bestparamsMLR = xgb_classifier.best_params_\n",
    "        param = {\n",
    "            'max_depth': bestparamsMLR.get('max_depth'),  # the maximum depth of each tree\n",
    "            'n_estimators': bestparamsMLR.get('n_estimators'), #N_Estimators\n",
    "            'eta': 0.6,  # the training step for each iteration\n",
    "            'silent': 1,  # logging mode - quiet\n",
    "            'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "            'num_class': 4}  # the number of classes that exist in this datset\n",
    "        num_round = 40  # the number of training iterations\n",
    "        \n",
    "        bst = xgb.train(param, self.dtrain, num_round)\n",
    "        preds = bst.predict(self.dtest)\n",
    "        \n",
    "        best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "        clsfrprecisionscore = precision_score(self.group_y_test, best_preds, average='macro')\n",
    "        \n",
    "        print('----------')\n",
    "        print('CLASSIFIER ACCURACY ON TEST DATA:')\n",
    "        print('Classifier Accuracy on Test Data: ',clsfrprecisionscore*100,'%')\n",
    "        \n",
    "        self.xgb_classifier = xgb_classifier\n",
    "        \n",
    "        if mltargetplanet == 'RemTot':\n",
    "            mainactiondata = self.remtot_nogroup_data_TEST\n",
    "        elif mltargetplanet == 'RemTarg':\n",
    "            mainactiondata = self.remtarg_nogroup_data_TEST\n",
    "        else:\n",
    "            mainactiondata = self.xi_nogroup_data_TEST\n",
    "            \n",
    "        mainactiondata[\"Group\"] = best_preds\n",
    "            \n",
    "        ######    \n",
    "            \n",
    "        mainactiondata.sort_values('Group')\n",
    "        \n",
    "        #Sorting Them Again\n",
    "        \n",
    "        newtest_g0 = mainactiondata[mainactiondata[\"Group\"] == 0]\n",
    "        newy_test_g0 = newtest_g0[mltargetplanet]\n",
    "        del newtest_g0[mltargetplanet]\n",
    "        newX_test_g0 = newtest_g0\n",
    "\n",
    "        ######\n",
    "        newtest_g1 = mainactiondata[mainactiondata[\"Group\"] == 1]\n",
    "        newy_test_g1 = newtest_g1[mltargetplanet]\n",
    "        del newtest_g1[mltargetplanet]\n",
    "        newX_test_g1 = newtest_g1\n",
    "\n",
    "        #######\n",
    "        newtest_g2 = mainactiondata[mainactiondata[\"Group\"] == 2]\n",
    "        newy_test_g2 = newtest_g2[mltargetplanet]\n",
    "        del newtest_g2[mltargetplanet]\n",
    "        newX_test_g2 = newtest_g2\n",
    "\n",
    "        #######\n",
    "        newtest_g3 = mainactiondata[mainactiondata[\"Group\"] == 3]\n",
    "        newy_test_g3 = newtest_g3[mltargetplanet]\n",
    "        del newtest_g3[mltargetplanet]\n",
    "        newX_test_g3 = newtest_g3\n",
    "\n",
    "        ###########################\n",
    "\n",
    "        self.newtestmatrixgroup = [newtest_g0,newtest_g1,newtest_g2,newtest_g3]\n",
    "        self.newtestxgroup = [newX_test_g0,newX_test_g1,newX_test_g2,newX_test_g3]\n",
    "        self.newtestygroup = [newy_test_g0,newy_test_g1,newy_test_g2,newy_test_g3]\n",
    "\n",
    "        frame = []\n",
    "        for i in range(0,4):\n",
    "            y_test_predsm = self.regressormatrix[i].predict(self.newtestxgroup[i])\n",
    "            self.newtestxgroup[i][mltargetplanet] = y_test_predsm\n",
    "            frame.append(self.newtestxgroup[i])\n",
    "\n",
    "        result = pd.concat(frame)\n",
    "        self.result = result\n",
    "\n",
    "        y_test_pred = result[mltargetplanet]\n",
    "        \n",
    "        y_test_pred.sort_index(inplace=True)\n",
    "        \n",
    "        if mltargetplanet == 'RemTot':\n",
    "        \n",
    "            self.remtot_nogroup_y_test.sort_index(inplace=True)\n",
    "            \n",
    "            print('----------')\n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(self.remtot_nogroup_y_test, y_test_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(self.remtot_nogroup_y_test, y_test_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(self.remtot_nogroup_y_test, y_test_pred))))\n",
    "            \n",
    "            self.remtotmse = metrics.mean_squared_error(self.remtot_nogroup_y_test, y_test_pred)\n",
    "            \n",
    "            self.remtotypred = y_test_pred\n",
    "            self.remtotyact = self.remtot_nogroup_y_test\n",
    "\n",
    "            return y_test_pred\n",
    "        \n",
    "        elif mltargetplanet == 'RemTarg':\n",
    "        \n",
    "            self.remtarg_nogroup_y_test.sort_index(inplace=True)\n",
    "\n",
    "            print('----------')\n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(self.remtarg_nogroup_y_test, y_test_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(self.remtarg_nogroup_y_test, y_test_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(self.remtarg_nogroup_y_test, y_test_pred))))\n",
    "            \n",
    "            self.remtargmse = metrics.mean_squared_error(self.remtarg_nogroup_y_test, y_test_pred)\n",
    "            \n",
    "            self.remtargypred = y_test_pred\n",
    "            self.remtargyact = self.remtarg_nogroup_y_test\n",
    "            \n",
    "            return y_test_pred\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            self.xi_nogroup_y_test.sort_index(inplace=True)\n",
    "\n",
    "            print('----------')\n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(self.xi_nogroup_y_test, y_test_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(self.xi_nogroup_y_test, y_test_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(self.xi_nogroup_y_test, y_test_pred))))\n",
    "            \n",
    "            self.ximse = metrics.mean_squared_error(self.xi_nogroup_y_test, y_test_pred)\n",
    "            \n",
    "            self.xiypred = y_test_pred\n",
    "            self.xiyact = self.xi_nogroup_y_test\n",
    "            \n",
    "            return y_test_pred\n",
    "    \n",
    "    \n",
    "    #------ANALYSIS CODE-------#\n",
    "    \n",
    "    def analysis(self,selectedmodel):\n",
    "        \n",
    "        self.selectedmodel = selectedmodel\n",
    "        \n",
    "        if self.selectedmodel == 'XGBoost':\n",
    "                    \n",
    "            if (self.metric2opt == 'custom'):\n",
    "                custom_scorer = metrics.make_scorer(self.custom_loss_func, greater_is_better =False)\n",
    "                self.metric=custom_scorer\n",
    "            print('                   Using the '+selectedmodel +' Model                   ')\n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TOTAL MASS ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_remtot=self.xgbGS('remtot')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_remtot, mse_remtot, y_predCV_remtot]=self.xgbCV_scores(self.remtot_nogroup_X_train, self.remtot_nogroup_y_train, best_params_remtot)\n",
    "            \n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_remtot),np.std(mse_remtot)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_remtot))))\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtot_nogroup_X_train,self.remtot_nogroup_y_train,y_predCV_remtot,0.25)\n",
    "            \n",
    "            #self.outlierdetector(self.remtot_nogroup_X_train,self.remtot_nogroup_y_train,y_predCV_remtot,0.25)\n",
    "        \n",
    "            xgb_final_remtot = self.xgbtrainmodel(self.remtot_nogroup_X_train, self.remtot_nogroup_y_train, best_params_remtot)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_remtot = self.xgbtest_unseendata(xgb_final_remtot,self.remtot_nogroup_X_test,self.remtot_nogroup_y_test)\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtot_nogroup_X_test,self.remtot_nogroup_y_test,y_test_pred_remtot,0.25)\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            print('==================== With Feature Generation ====================')\n",
    "            self.remtot_nogroup_full_X_train = self.createfeatures(self.remtot_nogroup_X_train)\n",
    "            self.remtot_nogroup_full_X_test = self.createfeatures(self.remtot_nogroup_X_test)\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_remtotfull=self.xgbGS('remtotfull')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_remtotfull, mse_remtotfull, y_predCV_remtotfull]=self.xgbCV_scores(self.remtot_nogroup_full_X_train, self.remtot_nogroup_y_train, best_params_remtotfull)\n",
    "            \n",
    "\n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_remtotfull),np.std(mse_remtotfull)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_remtotfull))))\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtot_nogroup_full_X_train,self.remtot_nogroup_y_train,y_predCV_remtotfull,0.25)\n",
    "            \n",
    "            xgb_final_remtotfull = self.xgbtrainmodel(self.remtot_nogroup_full_X_train, self.remtot_nogroup_y_train, best_params_remtotfull)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_remtotfull = self.xgbtest_unseendata(xgb_final_remtotfull,self.remtot_nogroup_full_X_test,self.remtot_nogroup_y_test)\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtot_nogroup_full_X_test,self.remtot_nogroup_y_test,y_test_pred_remtotfull,0.25)\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TARGET MASS ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_remtarg=self.xgbGS('remtarg')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_remtarg, mse_remtarg, y_predCV_remtarg]=self.xgbCV_scores(self.remtarg_nogroup_X_train, self.remtarg_nogroup_y_train, best_params_remtarg)\n",
    "            \n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_remtarg),np.std(mse_remtarg)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_remtarg))))\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtarg_nogroup_X_train,self.remtarg_nogroup_y_train,y_predCV_remtarg,0.25)\n",
    "        \n",
    "        \n",
    "            xgb_final_remtarg = self.xgbtrainmodel(self.remtarg_nogroup_X_train, self.remtarg_nogroup_y_train, best_params_remtarg)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_remtarg = self.xgbtest_unseendata(xgb_final_remtarg,self.remtarg_nogroup_X_test,self.remtarg_nogroup_y_test)\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtarg_nogroup_X_test,self.remtarg_nogroup_y_test,y_test_pred_remtarg,0.25)\n",
    "\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            print('==================== With Feature Generation ====================')\n",
    "            self.remtarg_nogroup_full_X_train = self.createfeatures(self.remtarg_nogroup_X_train)\n",
    "            self.remtarg_nogroup_full_X_test = self.createfeatures(self.remtarg_nogroup_X_test)\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_remtargfull=self.xgbGS('remtargfull')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_remtargfull, mse_remtargfull, y_predCV_remtargfull]=self.xgbCV_scores(self.remtarg_nogroup_full_X_train, self.remtarg_nogroup_y_train, best_params_remtargfull)\n",
    "            \n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_remtargfull),np.std(mse_remtargfull)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_remtargfull))))\n",
    "        \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtarg_nogroup_full_X_train,self.remtarg_nogroup_y_train,y_predCV_remtargfull,0.25)\n",
    "            \n",
    "        \n",
    "            xgb_final_remtargfull = self.xgbtrainmodel(self.remtarg_nogroup_full_X_train, self.remtarg_nogroup_y_train, best_params_remtargfull)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_remtargfull = self.xgbtest_unseendata(xgb_final_remtargfull,self.remtarg_nogroup_full_X_test,self.remtarg_nogroup_y_test) \n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.remtarg_nogroup_full_X_test,self.remtarg_nogroup_y_test,y_test_pred_remtargfull,0.25)\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            print('++++++++++ ACCRETION EFFICIENCY ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_xi=self.xgbGS('xi')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_xi, mse_xi, y_predCV_xi]=self.xgbCV_scores(self.xi_nogroup_X_train, self.xi_nogroup_y_train, best_params_xi)\n",
    "            \n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_xi),np.std(mse_xi)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_xi))))\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.xi_nogroup_X_train,self.xi_nogroup_y_train,y_predCV_xi,0.25)\n",
    "        \n",
    "            xgb_final_xi = self.xgbtrainmodel(self.xi_nogroup_X_train, self.xi_nogroup_y_train, best_params_xi)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_xi = self.xgbtest_unseendata(xgb_final_xi,self.xi_nogroup_X_test,self.xi_nogroup_y_test)\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.xi_nogroup_X_test,self.xi_nogroup_y_test,y_test_pred_xi,0.25)\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            print('==================== With Feature Generation ====================')\n",
    "            self.xi_nogroup_full_X_train = self.createfeatures(self.xi_nogroup_X_train)\n",
    "            self.xi_nogroup_full_X_test = self.createfeatures(self.xi_nogroup_X_test)\n",
    "            print('GRID SEARCH:')\n",
    "            best_params_xifull=self.xgbGS('xifull')\n",
    "            \n",
    "            print('----------')\n",
    "            print('TRAINING DATA:')\n",
    "            [score_xifull, mse_xifull, y_predCV_xifull]=self.xgbCV_scores(self.xi_nogroup_full_X_train, self.xi_nogroup_y_train, best_params_xifull)\n",
    "            \n",
    "            # To get scores in cross validation with Train data\n",
    "            #print('Training Data %s: %2f .... STDev: %2f ' %(self.metric2opt, np.mean(score_remtot), np.std(score_remtot)))\n",
    "            print('Training Data MSE: %2f .... STDev: %2f' %(np.mean(mse_xifull),np.std(mse_xifull)))\n",
    "            print('Training Data RMSE: %2f' %(np.sqrt(np.mean(mse_xifull))))\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.xi_nogroup_full_X_train,self.xi_nogroup_y_train,y_predCV_xifull,0.25)\n",
    "            \n",
    "        \n",
    "            xgb_final_xifull = self.xgbtrainmodel(self.xi_nogroup_full_X_train, self.xi_nogroup_y_train, best_params_xifull)\n",
    "            print('----------')\n",
    "            print('TEST DATA:')\n",
    "            y_test_pred_xifull = self.xgbtest_unseendata(xgb_final_xifull,self.xi_nogroup_full_X_test,self.xi_nogroup_y_test)\n",
    "            \n",
    "            print('')\n",
    "            self.outlierdetector(self.xi_nogroup_full_X_test,self.xi_nogroup_y_test,y_test_pred_xifull,0.25)\n",
    "            \n",
    "\n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            self.xgbremtotpred = y_test_pred_remtotfull\n",
    "            self.xgbremtargpred = y_test_pred_remtargfull\n",
    "            self.xgbxipred = y_test_pred_xifull\n",
    "            \n",
    "            scorearray = np.array([np.mean(mse_remtotfull),np.mean(mse_remtargfull),np.mean(mse_xifull)])\n",
    "            regressorlist = [xgb_final_remtot,xgb_final_remtarg,xgb_final_xi]\n",
    "            scorewinner = np.argmin(scorearray)\n",
    "            \n",
    "            if scorewinner == 0:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',np.mean(mse_remtotfull),' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TOTAL MASS')\n",
    "            elif scorewinner == 1:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',np.mean(mse_remtargfull),' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TARGET MASS')\n",
    "            else:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',np.mean(mse_xifull),' FOR MACHINE LEARNING TARGET - ACCRETION EFFICIENCY')\n",
    "        \n",
    "            trace_remtotfull_train = go.Scatter(x=self.remtot_nogroup_y_train,y=y_predCV_remtotfull, name=\"MLR Norm. to Total M - Train Data\",mode= 'markers',marker= dict(size= 3+3*self.remtot_nogroup_full_X_train['Impact Velocity'],line= dict(width=1), color= self.remtot_nogroup_full_X_train['Impact Angle'],colorscale='Reds',showscale=False))\n",
    "            trace_remtotfull_test = go.Scatter(x=self.remtot_nogroup_y_test,y=y_test_pred_remtotfull, name=\"MLR Norm. to Total M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.remtot_nogroup_full_X_test['Impact Velocity'],line= dict(width=1), color= self.remtot_nogroup_full_X_test['Impact Angle'],colorscale='Greens',showscale=False))\n",
    "            \n",
    "            trace_remtargfull_train = go.Scatter(x=self.remtarg_nogroup_y_train,y=y_predCV_remtargfull, name=\"MLR Norm. to Target M - Train Data\",mode= 'markers',marker= dict(size= 3+3*self.remtarg_nogroup_full_X_train['Impact Velocity'],line= dict(width=1), color= self.remtarg_nogroup_full_X_train['Impact Angle'],colorscale='Blues',showscale=False))\n",
    "            trace_remtargfull_test = go.Scatter(x=self.remtarg_nogroup_y_test,y=y_test_pred_remtargfull, name=\"MLR Norm. to Target M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.remtarg_nogroup_full_X_test['Impact Velocity'],line= dict(width=1), color= self.remtarg_nogroup_full_X_test['Impact Angle'],colorscale='Blackbody',showscale=False))\n",
    "\n",
    "            trace_xifull_train = go.Scatter(x=self.xi_nogroup_y_train,y=y_predCV_xifull, name=\"Xi - Train Data\",mode= 'markers',marker= dict(size= 3+3*self.xi_nogroup_full_X_train['Impact Velocity'],line= dict(width=1), color= self.xi_nogroup_full_X_train['Impact Angle'],colorscale='Hot',showscale=False))\n",
    "            trace_xifull_test = go.Scatter(x=self.xi_nogroup_y_test,y=y_test_pred_xifull, name=\"Xi - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.xi_nogroup_full_X_test['Impact Velocity'],line= dict(width=1), color= self.xi_nogroup_full_X_test['Impact Angle'],colorscale='Viridis',showscale=False))\n",
    "\n",
    "            datasetplot = [trace_remtotfull_train,trace_remtotfull_test,trace_remtargfull_train,trace_remtargfull_test,trace_xifull_train,trace_xifull_test]\n",
    "            #py.plot(datasetplot)\n",
    "                    \n",
    "            layout = go.Layout(title='Actual Vs Predicted Graphs',\n",
    "                          xaxis = dict(title='Actual', zeroline = False),\n",
    "                          yaxis = dict(title='Predicted',zeroline = False)\n",
    "                         )\n",
    "            fig = go.Figure(data=datasetplot, layout=layout)\n",
    "            return(py.iplot(fig))\n",
    "        \n",
    "        elif self.selectedmodel == 'Nested':\n",
    "                    \n",
    "            if (self.metric2opt == 'custom'):\n",
    "                custom_scorer = metrics.make_scorer(self.custom_loss_func, greater_is_better =False)\n",
    "                self.metric=custom_scorer\n",
    "                \n",
    "            print('                   Using the '+selectedmodel +' Model                   ')\n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TOTAL MASS ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "             \n",
    "            self.nest_main(self.remtot_wgroup_data_TRAIN,'RemTot')\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TARGET MASS ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "            \n",
    "            self.nest_main(self.remtarg_wgroup_data_TRAIN,'RemTarg')\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            print('++++++++++ ACCRETION EFFICIENCY ++++++++++')\n",
    "            print('')\n",
    "            print('==================== Original Four Features ====================')\n",
    "            \n",
    "            self.nest_main(self.xi_wgroup_data_TRAIN,'Xi')\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            scorearray = np.array([self.remtotmse,self.remtargmse,self.ximse])\n",
    "            scorewinner = np.argmin(scorearray)\n",
    "            \n",
    "            if scorewinner == 0:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',self.remtotmse,' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TOTAL MASS')\n",
    "            elif scorewinner == 1:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',self.remtargmse,' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TARGET MASS')\n",
    "            else:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',self.ximse,' FOR MACHINE LEARNING TARGET - ACCRETION EFFICIENCY')\n",
    "            \n",
    "            \n",
    "            trace_remtot_test = go.Scatter(x=self.remtotyact,y=self.remtotypred, name=\"MLR Norm. to Total M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Greens',showscale=False))\n",
    "            \n",
    "            trace_remtarg_test = go.Scatter(x=self.remtargyact,y=self.remtargypred, name=\"MLR Norm. to Target M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Blackbody',showscale=False))\n",
    "\n",
    "            trace_xi_test = go.Scatter(x=self.xiyact,y=self.xiypred, name=\"Xi - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Viridis',showscale=False))\n",
    "\n",
    "            datasetplot = [trace_remtot_test,trace_remtarg_test,trace_xi_test]\n",
    "            #py.plot(datasetplot)\n",
    "                    \n",
    "            layout = go.Layout(title='Actual Vs Predicted Graphs',\n",
    "                          xaxis = dict(title='Actual', zeroline = False),\n",
    "                          yaxis = dict(title='Predicted',zeroline = False)\n",
    "                         )\n",
    "            fig = go.Figure(data=datasetplot, layout=layout)\n",
    "            return(py.iplot(fig))\n",
    "            \n",
    "            #return y_test_pred_remtotfull\n",
    "            \n",
    "        \n",
    "        elif self.selectedmodel == 'Ensemble':\n",
    "            \n",
    "            xgb_remtot_pred = self.xgbremtotpred.sort_index(inplace=True)\n",
    "            xgb_remtarg_pred = self.xgbremtargpred.sort_index(inplace=True)\n",
    "            xgb_xi_pred = self.xgbxipred.sort_index(inplace=True)\n",
    "            \n",
    "            nested_remtot_pred = self.remtotypred.sort_index(inplace=True)\n",
    "            nested_remtarg_pred = self.remtargypred.sort_index(inplace=True)\n",
    "            nested_xi_pred = self.xiypred.sort_index(inplace=True)\n",
    "            \n",
    "            actual_remtot_test = self.remtot_nogroup_y_test.sort_index(inplace=True)\n",
    "            actual_remtarg_test = self.remtarg_nogroup_y_test.sort_index(inplace=True)\n",
    "            actual_xi_test = self.xi_nogroup_y_test.sort_index(inplace=True)\n",
    "            \n",
    "            aggregate_remtot_pred = (xgb_remtot_pred+nested_remtot_pred)/2\n",
    "            aggregate_remtarg_pred = (xgb_remtarg_pred+nested_remtarg_pred)/2\n",
    "            aggregate_xi_pred = (xgb_xi_pred+nested_xi_pred)/2\n",
    "            \n",
    "            \n",
    "            print('                   Using the '+selectedmodel +' Model                   ')\n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TOTAL MASS ++++++++++')\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(actual_remtot_test, aggregate_remtot_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(actual_remtot_test, aggregate_remtot_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(actual_remtot_test, aggregate_remtot_pred))))\n",
    "            \n",
    "            \n",
    "            agremtotmse = metrics.mean_squared_error(actual_remtot_test, aggregate_remtot_pred)\n",
    "            \n",
    "            print('')\n",
    "            print('++++++++++ MASS OF REMNANT NORMALIZED TO TARGET MASS ++++++++++')\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(actual_remtarg_test, aggregate_remtarg_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(actual_remtarg_test, aggregate_remtarg_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(actual_remtarg_test, aggregate_remtarg_pred))))\n",
    "            \n",
    "            agremtargmse = metrics.mean_squared_error(actual_remtarg_test, aggregate_remtarg_pred)\n",
    "            \n",
    "            print('')\n",
    "            print('++++++++++ ACCRETION EFFICIENCY ++++++++++')\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "            print('TESTING DATA SCORES:')\n",
    "            #print('%s : .....%2f' %(self.metric2opt, self.custom_loss_func(self.xgb_y_test, y_test_pred)))\n",
    "            print('MAE : ....%2f' %(metrics.mean_absolute_error(actual_xi_test, aggregate_xi_pred)))\n",
    "            print('MSE : ....%2f' %(metrics.mean_squared_error(actual_xi_test, aggregate_xi_pred)))\n",
    "            print('RMSE : ....%2f' %(np.sqrt(metrics.mean_squared_error(actual_xi_test, aggregate_xi_pred))))\n",
    "            \n",
    "            agximse = metrics.mean_squared_error(actual_xi_test, aggregate_xi_pred)\n",
    "            \n",
    "            print('')\n",
    "            print('')\n",
    "            \n",
    "            scorearray = np.array([agremtotmse,agremtargmse,agximse])\n",
    "            scorewinner = np.argmin(scorearray)\n",
    "            \n",
    "            if scorewinner == 0:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',agremtotmse,' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TOTAL MASS')\n",
    "            elif scorewinner == 1:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',agremtargmse,' FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TARGET MASS')\n",
    "            else:\n",
    "                print('BEST TRAIN MSE SCORE WAS: ',agximse,' FOR MACHINE LEARNING TARGET - ACCRETION EFFICIENCY')\n",
    "            \n",
    "            \n",
    "            trace_remtot_ag = go.Scatter(x=actual_remtot_test,y=aggregate_remtot_pred, name=\"MLR Norm. to Total M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Greens',showscale=False))\n",
    "            \n",
    "            trace_remtarg_ag = go.Scatter(x=actual_remtarg_test,y=aggregate_remtarg_pred, name=\"MLR Norm. to Target M - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Blackbody',showscale=False))\n",
    "\n",
    "            trace_xi_ag = go.Scatter(x=actual_xi_test,y=aggregate_xi_pred, name=\"Xi - Test Data\",mode= 'markers',marker= dict(size= 3+3*self.result['Impact Velocity'],line= dict(width=1), color=self.result['Impact Angle'],colorscale='Viridis',showscale=False))\n",
    "\n",
    "            datasetplot = [trace_remtot_ag,trace_remtarg_ag,trace_xi_ag]\n",
    "            #py.plot(datasetplot)\n",
    "                    \n",
    "            layout = go.Layout(title='Actual Vs Predicted Graphs',\n",
    "                          xaxis = dict(title='Actual', zeroline = False),\n",
    "                          yaxis = dict(title='Predicted',zeroline = False)\n",
    "                         )\n",
    "            fig = go.Figure(data=datasetplot, layout=layout)\n",
    "            return(py.iplot(fig))\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            print(\"The selected model is invalid, please select either of the following:\")\n",
    "            print(\"1. XGBoost\")\n",
    "            print(\"2. Nested\")\n",
    "            print(\"3. Ensemble\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Using the XGBoost Model                   \n",
      "\n",
      "++++++++++ MASS OF REMNANT NORMALIZED TO TOTAL MASS ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 9, 'n_estimators': 65}\n",
      "Best Metric Score: 0.00892347478082458\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.008924 .... STDev: 0.001470\n",
      "Training Data RMSE: 0.094466\n",
      "\n",
      "Number of samples predicted poorly: 13\n",
      "MSE of poorly-predicted samples:  0.128418\n",
      "MSE of well-predicted samples:  0.006874\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Target Mass: .... 0.016529\n",
      "Impactor Mass/Target Mass: .... 0.214876\n",
      "Impact Velocity: .... 0.471074\n",
      "Impact Angle: .... 0.297521\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.065055\n",
      "MSE : ....0.006762\n",
      "RMSE : ....0.082233\n",
      "\n",
      "Number of samples predicted poorly: 3\n",
      "MSE of poorly-predicted samples:  0.106890\n",
      "MSE of well-predicted samples:  0.005584\n",
      "\n",
      "\n",
      "==================== With Feature Generation ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 5, 'n_estimators': 95}\n",
      "Best Metric Score: 0.0074663795584109195\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.007467 .... STDev: 0.001451\n",
      "Training Data RMSE: 0.086410\n",
      "\n",
      "Number of samples predicted poorly: 19\n",
      "MSE of poorly-predicted samples:  0.126898\n",
      "MSE of well-predicted samples:  0.004449\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Impactor Mass/Target Mass: .... 0.190909\n",
      "Impact Velocity: .... 0.390909\n",
      "Impact Angle: .... 0.127273\n",
      "l: .... 0.054545\n",
      "mualpha: .... 0.018182\n",
      "vel2 x angle: .... 0.090909\n",
      "vel3 x angle: .... 0.127273\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.052430\n",
      "MSE : ....0.005339\n",
      "RMSE : ....0.073071\n",
      "\n",
      "Number of samples predicted poorly: 3\n",
      "MSE of poorly-predicted samples:  0.113256\n",
      "MSE of well-predicted samples:  0.004070\n",
      "\n",
      "\n",
      "++++++++++ MASS OF REMNANT NORMALIZED TO TARGET MASS ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 9, 'n_estimators': 95}\n",
      "Best Metric Score: 0.015581696913587325\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.015581 .... STDev: 0.002395\n",
      "Training Data RMSE: 0.124824\n",
      "\n",
      "Number of samples predicted poorly: 54\n",
      "MSE of poorly-predicted samples:  0.135173\n",
      "MSE of well-predicted samples:  0.006575\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Target Mass: .... 0.040230\n",
      "Impactor Mass/Target Mass: .... 0.206897\n",
      "Impact Velocity: .... 0.448276\n",
      "Impact Angle: .... 0.304598\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.069816\n",
      "MSE : ....0.010670\n",
      "RMSE : ....0.103295\n",
      "\n",
      "Number of samples predicted poorly: 13\n",
      "MSE of poorly-predicted samples:  0.114594\n",
      "MSE of well-predicted samples:  0.005156\n",
      "\n",
      "\n",
      "==================== With Feature Generation ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 9, 'n_estimators': 95}\n",
      "Best Metric Score: 0.013559343417508278\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.013559 .... STDev: 0.003683\n",
      "Training Data RMSE: 0.116443\n",
      "\n",
      "Number of samples predicted poorly: 34\n",
      "MSE of poorly-predicted samples:  0.192844\n",
      "MSE of well-predicted samples:  0.005288\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Target Mass: .... 0.006098\n",
      "Impactor Mass/Target Mass: .... 0.201220\n",
      "Impact Velocity: .... 0.286585\n",
      "Impact Angle: .... 0.079268\n",
      "log Impactor log Target: .... 0.024390\n",
      "QR: .... 0.006098\n",
      "l: .... 0.115854\n",
      "mualpha: .... 0.048780\n",
      "QRmu: .... 0.018293\n",
      "vel x angle: .... 0.012195\n",
      "vel2 x angle: .... 0.109756\n",
      "vel3 x angle: .... 0.085366\n",
      "exp vel x angle: .... 0.006098\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.057531\n",
      "MSE : ....0.009355\n",
      "RMSE : ....0.096719\n",
      "\n",
      "Number of samples predicted poorly: 9\n",
      "MSE of poorly-predicted samples:  0.146694\n",
      "MSE of well-predicted samples:  0.004390\n",
      "\n",
      "\n",
      "++++++++++ ACCRETION EFFICIENCY ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 11, 'n_estimators': 65}\n",
      "Best Metric Score: 0.044883780129418835\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.044875 .... STDev: 0.012317\n",
      "Training Data RMSE: 0.211837\n",
      "\n",
      "Number of samples predicted poorly: 120\n",
      "MSE of poorly-predicted samples:  0.238007\n",
      "MSE of well-predicted samples:  0.009285\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Target Mass: .... 0.217905\n",
      "Impactor Mass/Target Mass: .... 0.079392\n",
      "Impact Velocity: .... 0.349662\n",
      "Impact Angle: .... 0.353041\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.110009\n",
      "MSE : ....0.030186\n",
      "RMSE : ....0.173742\n",
      "\n",
      "Number of samples predicted poorly: 25\n",
      "MSE of poorly-predicted samples:  0.227961\n",
      "MSE of well-predicted samples:  0.008966\n",
      "\n",
      "\n",
      "==================== With Feature Generation ====================\n",
      "GRID SEARCH:\n",
      "Performing GridSearchCV with Metric: neg_mean_squared_error\n",
      "Best Parameters: {'max_depth': 11, 'n_estimators': 55}\n",
      "Best Metric Score: 0.041064123992582996\n",
      "----------\n",
      "TRAINING DATA:\n",
      "Training Data MSE: 0.041050 .... STDev: 0.016367\n",
      "Training Data RMSE: 0.202608\n",
      "\n",
      "Number of samples predicted poorly: 91\n",
      "MSE of poorly-predicted samples:  0.290407\n",
      "MSE of well-predicted samples:  0.007696\n",
      "----------\n",
      "NON-ZERO FEATURE IMPORTANCES:\n",
      "Target Mass: .... 0.022177\n",
      "Impactor Mass/Target Mass: .... 0.038306\n",
      "Impact Velocity: .... 0.209677\n",
      "Impact Angle: .... 0.080645\n",
      "Impactor Mass: .... 0.004032\n",
      "log Impactor log Target: .... 0.032258\n",
      "QR: .... 0.048387\n",
      "B: .... 0.080645\n",
      "l: .... 0.114919\n",
      "alpha: .... 0.082661\n",
      "mualpha: .... 0.050403\n",
      "QRmu: .... 0.012097\n",
      "vel x angle: .... 0.044355\n",
      "vel x angle2: .... 0.002016\n",
      "vel2 x angle: .... 0.074597\n",
      "vel3 x angle: .... 0.092742\n",
      "exp vel x angle: .... 0.010081\n",
      "----------\n",
      "TEST DATA:\n",
      "Test Data Scores:\n",
      "MAE : ....0.100197\n",
      "MSE : ....0.032110\n",
      "RMSE : ....0.179193\n",
      "\n",
      "Number of samples predicted poorly: 26\n",
      "MSE of poorly-predicted samples:  0.263149\n",
      "MSE of well-predicted samples:  0.006218\n",
      "\n",
      "\n",
      "BEST TRAIN MSE SCORE WAS:  0.007466625271690493  FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TOTAL MASS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emaad/4818.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatatp = pd.read_csv('collisions.csv') #Importing Data\n",
    "run = MLCollisions(dataframe=alldatatp, metric2opt='neg_mean_squared_error', FI=True)\n",
    "run.analysis('XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Using the Nested Model                   \n",
      "\n",
      "++++++++++ MASS OF REMNANT NORMALIZED TO TOTAL MASS ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "CLASS-SPECIFIC REGRESSOR TRAINING:\n",
      "Class 0 Training Data MSE: 0.012270 .... STDev: 0.003140\n",
      "Class 0 Training Data RMSE: 0.110768\n",
      "\n",
      "Class 1 Training Data MSE: 0.004720 .... STDev: 0.006247\n",
      "Class 1 Training Data RMSE: 0.068700\n",
      "\n",
      "Class 2 Training Data MSE: 0.004289 .... STDev: 0.000798\n",
      "Class 2 Training Data RMSE: 0.065489\n",
      "\n",
      "Class 3 Training Data MSE: 0.009411 .... STDev: 0.002139\n",
      "Class 3 Training Data RMSE: 0.097012\n",
      "----------\n",
      "CLASSIFIER ACCURACY ON TEST DATA:\n",
      "Classifier Accuracy on Test Data:  96.7758367883507 %\n",
      "----------\n",
      "TESTING DATA SCORES:\n",
      "MAE : ....0.063645\n",
      "MSE : ....0.008489\n",
      "RMSE : ....0.092134\n",
      "\n",
      "\n",
      "++++++++++ MASS OF REMNANT NORMALIZED TO TARGET MASS ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "CLASS-SPECIFIC REGRESSOR TRAINING:\n",
      "Class 0 Training Data MSE: 0.014973 .... STDev: 0.001555\n",
      "Class 0 Training Data RMSE: 0.122366\n",
      "\n",
      "Class 1 Training Data MSE: 0.000137 .... STDev: 0.000183\n",
      "Class 1 Training Data RMSE: 0.011692\n",
      "\n",
      "Class 2 Training Data MSE: 0.009782 .... STDev: 0.001897\n",
      "Class 2 Training Data RMSE: 0.098903\n",
      "\n",
      "Class 3 Training Data MSE: 0.014371 .... STDev: 0.004322\n",
      "Class 3 Training Data RMSE: 0.119878\n",
      "----------\n",
      "CLASSIFIER ACCURACY ON TEST DATA:\n",
      "Classifier Accuracy on Test Data:  96.7758367883507 %\n",
      "----------\n",
      "TESTING DATA SCORES:\n",
      "MAE : ....0.077039\n",
      "MSE : ....0.015193\n",
      "RMSE : ....0.123262\n",
      "\n",
      "\n",
      "++++++++++ ACCRETION EFFICIENCY ++++++++++\n",
      "\n",
      "==================== Original Four Features ====================\n",
      "CLASS-SPECIFIC REGRESSOR TRAINING:\n",
      "Class 0 Training Data MSE: 0.045429 .... STDev: 0.019347\n",
      "Class 0 Training Data RMSE: 0.213140\n",
      "\n",
      "Class 1 Training Data MSE: 0.001562 .... STDev: 0.001648\n",
      "Class 1 Training Data RMSE: 0.039524\n",
      "\n",
      "Class 2 Training Data MSE: 0.052906 .... STDev: 0.007261\n",
      "Class 2 Training Data RMSE: 0.230013\n",
      "\n",
      "Class 3 Training Data MSE: 0.035637 .... STDev: 0.018212\n",
      "Class 3 Training Data RMSE: 0.188778\n",
      "----------\n",
      "CLASSIFIER ACCURACY ON TEST DATA:\n",
      "Classifier Accuracy on Test Data:  96.7758367883507 %\n",
      "----------\n",
      "TESTING DATA SCORES:\n",
      "MAE : ....0.120581\n",
      "MSE : ....0.042097\n",
      "RMSE : ....0.205176\n",
      "\n",
      "\n",
      "BEST TRAIN MSE SCORE WAS:  0.008488598872680343  FOR MACHINE LEARNING TARGET - MASS OF LARGEST REMNANT NORMALIZED TO TOTAL MASS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emaad/4820.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatatp = pd.read_csv('collisions.csv') #Importing Data\n",
    "run = MLCollisions(dataframe=alldatatp, metric2opt='neg_mean_squared_error', FI=True)\n",
    "run.analysis('Nested')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
